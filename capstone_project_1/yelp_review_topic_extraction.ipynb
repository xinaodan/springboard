{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Review LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Latent Dirichlet Allocation to extract the topics from the yelp reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376702 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AakkkTuGZA2KBodKi2_u8A</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-16 00:37:14</td>\n",
       "      <td>1</td>\n",
       "      <td>JVcjMhlavKKn3UIt9p9OXA</td>\n",
       "      <td>1</td>\n",
       "      <td>I cannot believe how things have changed in 3 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>TpyOT5E16YASd7EWjLQlrw</td>\n",
       "      <td>...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.649674</td>\n",
       "      <td>-79.435116</td>\n",
       "      <td>Pho Phuong</td>\n",
       "      <td>M6K 1T9</td>\n",
       "      <td>55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AakkkTuGZA2KBodKi2_u8A</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-24 01:45:02</td>\n",
       "      <td>0</td>\n",
       "      <td>vKhtzhPUz9RJbllyvHm3qA</td>\n",
       "      <td>3</td>\n",
       "      <td>Pretty good, food,, about the same as other vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>G-9ujgKmc1J2k7HSqXszsw</td>\n",
       "      <td>...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.649674</td>\n",
       "      <td>-79.435116</td>\n",
       "      <td>Pho Phuong</td>\n",
       "      <td>M6K 1T9</td>\n",
       "      <td>55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AakkkTuGZA2KBodKi2_u8A</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-12 00:25:23</td>\n",
       "      <td>0</td>\n",
       "      <td>Je6AF9sTKwXwOVw2YHR1dg</td>\n",
       "      <td>5</td>\n",
       "      <td>I've been going to this place since it opened ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA4sslQXta6U263fqzwKiw</td>\n",
       "      <td>...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.649674</td>\n",
       "      <td>-79.435116</td>\n",
       "      <td>Pho Phuong</td>\n",
       "      <td>M6K 1T9</td>\n",
       "      <td>55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AakkkTuGZA2KBodKi2_u8A</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 06:03:17</td>\n",
       "      <td>0</td>\n",
       "      <td>b_xVF8U5Vqljz58OUEjqgA</td>\n",
       "      <td>4</td>\n",
       "      <td>One of the best Vietnamese places I`ve tried i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1fNQRju9gmoCEvbPQBSo7w</td>\n",
       "      <td>...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.649674</td>\n",
       "      <td>-79.435116</td>\n",
       "      <td>Pho Phuong</td>\n",
       "      <td>M6K 1T9</td>\n",
       "      <td>55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AakkkTuGZA2KBodKi2_u8A</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-30 16:46:24</td>\n",
       "      <td>0</td>\n",
       "      <td>vFPpG1xDBSWcvy_165fxKg</td>\n",
       "      <td>3</td>\n",
       "      <td>This place is just ok. Nice atmosphere, big op...</td>\n",
       "      <td>0</td>\n",
       "      <td>fYJGKhZK2FZckYWDMdCooA</td>\n",
       "      <td>...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.649674</td>\n",
       "      <td>-79.435116</td>\n",
       "      <td>Pho Phuong</td>\n",
       "      <td>M6K 1T9</td>\n",
       "      <td>55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id  cool                 date  funny  \\\n",
       "0           0  AakkkTuGZA2KBodKi2_u8A     0  2012-07-16 00:37:14      1   \n",
       "1           1  AakkkTuGZA2KBodKi2_u8A     0  2014-02-24 01:45:02      0   \n",
       "2           2  AakkkTuGZA2KBodKi2_u8A     0  2016-02-12 00:25:23      0   \n",
       "3           3  AakkkTuGZA2KBodKi2_u8A     0  2013-05-07 06:03:17      0   \n",
       "4           4  AakkkTuGZA2KBodKi2_u8A     0  2011-11-30 16:46:24      0   \n",
       "\n",
       "                review_id  stars_x  \\\n",
       "0  JVcjMhlavKKn3UIt9p9OXA        1   \n",
       "1  vKhtzhPUz9RJbllyvHm3qA        3   \n",
       "2  Je6AF9sTKwXwOVw2YHR1dg        5   \n",
       "3  b_xVF8U5Vqljz58OUEjqgA        4   \n",
       "4  vFPpG1xDBSWcvy_165fxKg        3   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  I cannot believe how things have changed in 3 ...       1   \n",
       "1  Pretty good, food,, about the same as other vi...       0   \n",
       "2  I've been going to this place since it opened ...       0   \n",
       "3  One of the best Vietnamese places I`ve tried i...       1   \n",
       "4  This place is just ok. Nice atmosphere, big op...       0   \n",
       "\n",
       "                  user_id  ...     city  \\\n",
       "0  TpyOT5E16YASd7EWjLQlrw  ...  Toronto   \n",
       "1  G-9ujgKmc1J2k7HSqXszsw  ...  Toronto   \n",
       "2  NA4sslQXta6U263fqzwKiw  ...  Toronto   \n",
       "3  1fNQRju9gmoCEvbPQBSo7w  ...  Toronto   \n",
       "4  fYJGKhZK2FZckYWDMdCooA  ...  Toronto   \n",
       "\n",
       "                                               hours is_open   latitude  \\\n",
       "0  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...       1  43.649674   \n",
       "1  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...       1  43.649674   \n",
       "2  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...       1  43.649674   \n",
       "3  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...       1  43.649674   \n",
       "4  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...       1  43.649674   \n",
       "\n",
       "   longitude        name  postal_code  review_count stars_y state  \n",
       "0 -79.435116  Pho Phuong      M6K 1T9            55     3.5    ON  \n",
       "1 -79.435116  Pho Phuong      M6K 1T9            55     3.5    ON  \n",
       "2 -79.435116  Pho Phuong      M6K 1T9            55     3.5    ON  \n",
       "3 -79.435116  Pho Phuong      M6K 1T9            55     3.5    ON  \n",
       "4 -79.435116  Pho Phuong      M6K 1T9            55     3.5    ON  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read toronto restaurant review data\n",
    "# Read data from gcp\n",
    "# df = pd.read_csv('gs://yelp_review_toronto_restaurant/toronto_restaurant_review.csv', index_col=0)\n",
    "# Read data from local file\n",
    "df = pd.read_csv('toronto_restaurant_review.csv')\n",
    "toronto_restaurant_review = df.text\n",
    "\n",
    "# Preview review data\n",
    "print(f'{df.shape[0]} reviews')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert acountlection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# LDA model\n",
    "lda = LatentDirichletAllocation(max_iter=5, \n",
    "                                learning_method='online', learning_offset=50., \n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lda(data, vectorizer, lda):\n",
    "    trr = vectorizer.fit_transform(data)\n",
    "    lda = LatentDirichletAllocation(max_iter=5, \n",
    "                                    learning_method='online', learning_offset=50., \n",
    "                                    random_state=0).fit(trr)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the method to print topic words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the method to return topic words as List\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    top_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words.append(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_lda(toronto_restaurant_review, vectorizer, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: pizza pasta italian shawarma market toppings falafel kensington thin gourmet veal dough bulgogi italy vermicelli delight style prosciutto hoof pepperoni\n",
      "Topic #1: the was and it we were to of for but had with good very my not on that food ordered\n",
      "Topic #2: the and is food great for to are place this in good service very of it you here have my\n",
      "Topic #3: and chicken the rice sushi with of soup thai spicy ramen noodles fried beef in pork is curry rolls sauce\n",
      "Topic #4: the to it is you and of that in for but they this not have if are on place so\n",
      "Topic #5: and of the bar with on beer great drinks night patio music drink in wine for to selection an nice\n",
      "Topic #6: the and with of was cheese on it fries burger sauce chicken in my sandwich had to salad sweet fried\n",
      "Topic #7: the to and we was our my for us were that had food of she at he in they service\n",
      "Topic #8: coffee tea cream ice cake chocolate dessert cheesecake dim cafe sum milk with desserts latte matcha crepe cup green their\n",
      "Topic #9: la de elsewhere guu izakaya al sake le el uni carte spanish un dente aburi et siu omakase paella est\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(model, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some words in the topic do not contribute to the undersanding of the topics (words like the, was, and, it etc.).\n",
    "\n",
    "Let's tunning the parameters to make a better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning The Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop_word\n",
    "The first thing we'll try is to specify stop word which doesn't give much information in representing the content of the text. The stop words will be removed from the document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: fish toronto tacos best beer chips jerk mexican taco gem ve city roti local hidden beers indian great authentic love\n",
      "Topic #1: pizza pasta italian sauce wine cheese crust bread tomato pizzas oil fresh mushrooms sea truffle spaghetti gnocchi slice risotto veal\n",
      "Topic #2: place like bar just location good area don little street people menu nice open new really want patio right tables\n",
      "Topic #3: vegetarian vegan overpriced shawarma gluten greek original options comfort fare exceptional falafel salsa danforth hummus uncle le la wing souvlaki\n",
      "Topic #4: food just time order didn service like table don came asked ordered minutes said did restaurant got server people bad\n",
      "Topic #5: food good great place service really restaurant time nice definitely menu delicious friendly amazing wait try ve staff dinner come\n",
      "Topic #6: dish dessert salad steak cake sauce lobster ordered cooked sweet served duck cheese came delicious bread meal perfectly cheesecake like\n",
      "Topic #7: fries chicken burger sandwich cheese meat sauce fried burgers pork poutine onion good bbq bun beef pulled like toppings bacon\n",
      "Topic #8: chicken rice good sushi soup spicy like thai beef sauce ramen food noodles fried place pork ordered really curry dishes\n",
      "Topic #9: coffee brunch tea breakfast ice cream eggs like good sweet cafe milk try toast chocolate really love delicious fresh waffles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "model = fit_lda(toronto_restaurant_review, vectorizer, lda)\n",
    "print_top_words(model, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the stop words removed, we have more meaningful words to represent the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_df and min_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document frequency (df) shows how frequent a specific word shows up in all the documents.\n",
    "\n",
    "By specifying max_df, the vectorizer ignores all the words whose df is higher than the threshold.\n",
    "By specifying min_df, the vectorizer ignores all the words whose df is lower than the threshold.\n",
    "\n",
    "If a word appears only in few documents, it probably doesn't contribute to understanding the topic of the documents.\n",
    "In a similar way, if a word appears in all documents, it can probably be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: menu restaurant wine steak dish great pasta dinner meal service salad dessert experience delicious night dishes good nice main lobster\n",
      "Topic #1: food great place good service friendly staff nice delicious definitely amazing best really love restaurant ve recommend atmosphere toronto menu\n",
      "Topic #2: sushi fish good fresh roll tacos japanese chips place sashimi rolls music burrito lunch small quality menu mexican price live\n",
      "Topic #3: chicken rice good soup sauce fried beef ordered pork spicy like ramen dish meat noodles really dishes hot curry taste\n",
      "Topic #4: coffee brunch cream tea sweet ice breakfast like eggs chocolate cake good dessert try really cheesecake delicious got just milk\n",
      "Topic #5: pizza fries burger cheese good sandwich beer chicken great sauce meat wings burgers try poutine salad really best sandwiches ordered\n",
      "Topic #6: like place food just don ve good better really time think know bad want people eat way make say thing\n",
      "Topic #7: food came time table service ordered got wait didn order minutes just server good people went place night took restaurant\n",
      "Topic #8: toronto street bar location st located west new queen yonge market area parking north king space basic city near la\n",
      "Topic #9: said order asked service restaurant staff customers customer told manager ago experience did owner rude called know free review worst\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the word if it appears in more than 80% of the documents \n",
    "max_df = 0.8\n",
    "# Remove the word if it appears in less than 5 documents\n",
    "min_df = 5\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
    "model = fit_lda(toronto_restaurant_review, vectorizer, lda)\n",
    "print_top_words(model, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above words in topics, we can see that:\n",
    "\n",
    "* Topic 1: Good restaurant and service\n",
    "* Topic 2: Japanese and Mexican food\n",
    "* Topic 4: Breakfast and dessert \n",
    "* Topic 5: Bar and comfort food\n",
    "* Topic 8: Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ngram_range and token_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: pizza dessert cream pasta ice cake tea chocolate sweet cheese bread ice cream cheesecake dim sum desserts dim sum delicious crust milk\n",
      "Topic #1: food t order service time ordered came wait minutes asked table took got said didn didn t told server long did\n",
      "Topic #2: t s like good just really place don don t m ve didn didn t wasn t wasn pretty think try got food\n",
      "Topic #3: chicken sauce fried rice dish pork beef soup ordered spicy meat dishes noodles hot curry shrimp came flavour crispy cooked\n",
      "Topic #4: sandwich coffee brunch beer breakfast cheese eggs bacon patio great french fries good sandwiches wings delicious menu toast nice bread\n",
      "Topic #5: s restaurant night bar experience place food menu people table like drinks just time dinner friends service server drink group\n",
      "Topic #6: great food place service good friendly delicious amazing best definitely staff love toronto nice recommend restaurant atmosphere ve thai really\n",
      "Topic #7: burger fries fish tacos chips burgers s burrito free mexican cheese fresh taco bun street toppings st onion queen poutine\n",
      "Topic #8: 5 good lunch price small 3 food place 4 2 s salad pretty quality bit quite service 10 portion 1\n",
      "Topic #9: sushi ramen roll japanese salmon korean rolls sashimi fish rice tuna miso spicy tempura ayce fresh pieces kimchi restaurant udon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_range = (1, 2)\n",
    "token_pattern = r'\\b\\w+\\b'\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram_range, token_pattern=token_pattern)\n",
    "model = fit_lda(toronto_restaurant_review, vectorizer, lda)\n",
    "print_top_words(model, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like using bigram doesn't give us much improvement on understanding the topic. We'll keep using the single word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term-Frequency Times Inverse Document-Frequency)\n",
    "Some words in the text corpus give less meaningful information ('a', 'the' in English). Tf-idf can re-weight the count features into floating point value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: criminal bayildi beer preference burgers excellent arrived outside closing really bums bit gamey better santouka app love bites special cool innovative bun noodles bourgeois cabana la anthony rose choice served add sort classic margherita compared chinese\n",
      "Topic #1: boston pizza coconut gelato 407 clams way benny really alright pork birthday lobster classic neighbourhood 40c beach food big chewy alright pretty cheaper fish beginning said burnt cheese bland worst box regular authentic okonomiyaki athens restaurant brunch atmosphere\n",
      "Topic #2: complain try 30 reservations covered huge concept work bits sauce bites sauce cakes bought base want bit air cozy experience crisply afternoon breakfast cream churro bartenders complemented pork complain rave complaints enjoy business thing beer looking cafe huge\n",
      "Topic #3: bigger 9 range apt description company overall bated breath comfortable benches cooked oven aesthetics service cheap options bland menu available 1 cooked crisp bits plate aand ask want cook dinner advertising 5 50 ate bbq bartender way\n",
      "Topic #4: board taste bowl plain arrived asked crab lemon bit realized classic fare amazing doubt bringing meals accessible food casual resto brownish colour came deconstructed afternoon 2pm chefs owners connaisseur amazingness amazing overly 30 overall buns price clean cheerful\n",
      "Topic #5: begin friends 10 crepe battered served care add come 30 came stacked chocolate chips best brownie costs associated amazing tons chicken salted alternative rock addictive taste ate walked case burger answer phone better yeah child service booking reservations bowls portion\n",
      "Topic #6: better stuff coworker decided average tried baltimore based restaurants chicken cubes catastrophic ask fries congress buey 30am weekday bright lovely burger stomach creamy yummy buns ordered croatian car half choose pay certain food 3 hour\n",
      "Topic #7: asked details big ingredients boyfriend weekend creamy salad bad 40 choice filling average poutine cooked appreciated appetizer expecting chili bean bowl spring bakery bun authentic noodles clean comfortable coarsely add cherry 14 bit awful rude actually fit accommodated easily\n",
      "Topic #8: case eating busy great coffees delicious care reviews ceiling beautiful crispy halibut burnt buns beer soju 7 food created bad came keg best definitely beans excellent cozy space charming neighbourhood best taking budae jjigae chinese chinese beef sticky cherry crumble\n",
      "Topic #9: bad came burger warm cash thankfully bread bread childhood favorite card signed completely went apart cheese 24 food check super broccoli tofu actually food 5 wait 50 pint buy bottled birthday looking brought pasta absolutely maybe chef dessert chicken thigh\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "model = fit_lda(toronto_restaurant_review, tfidf, lda)\n",
    "print_top_words(model, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that some new and confusing words show up in the result (criminal, aesthetics etc.). Tf-idf actually makes it harder to understand the topics. This may be caused by that those words are rarely showed up in the documents (reviews), so they are assigned with more weights than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics for Single Restaurant Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the restaurant which has most comments\n",
    "business_id_with_most_comments = df.business_id.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The restaurant with most comments in Toronto is: Pai Northern Thai Kitchen\n",
      "The score is: 4.5\n"
     ]
    }
   ],
   "source": [
    "# For the sake of own my interest, print the name and score of this restaurant\n",
    "# Unfortunately, name of the restaurant is in business.json, I looked it up and hard-coded the name here\n",
    "restaurant_name = 'Pai Northern Thai Kitchen'\n",
    "restaurant_score = df[df.business_id == business_id_with_most_comments].stars_y.iloc[0]\n",
    "print(f'The restaurant with most comments in Toronto is: {restaurant_name}')\n",
    "print(f'The score is: {restaurant_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all comments for the restaurant\n",
    "review_for_single_restaurant = df[df.business_id == business_id_with_most_comments].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 3\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5, \n",
    "                                learning_method='online', learning_offset=50., \n",
    "                                random_state=0)\n",
    "lda_single_restaurant = fit_lda(review_for_single_restaurant, vectorizer, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: thai curry pad food place khao rice dish good ve chicken ordered best really pai sauce beef great green soi\n",
      "Topic #1: food place good thai great service wait time restaurant table really just like menu came pai definitely make come busy\n",
      "Topic #2: thai food pad service just like spicy taste know order pai place good bit did thought ice high morning don\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda_single_restaurant, vectorizer.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topic 1: Type of food\n",
    "* Topic 2: Busy place\n",
    "* Topic 3: NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore the topics extracted from yelp's toronto restaurant review using LDA and how the parameters affect the result of the topics.\n",
    "\n",
    "Due to the limited resource of the project, we'll stop here. However, the parameters can be further tuned to get more interpretable topics. Unsupervised learning can also be applied to cluster the topics to categorise them.\n",
    "\n",
    "As we notice, human judgement is still required for the interpretation of the feature words in the topics. However, if the reivew has pre-defined topics labelled, the feature words can be used to train a classifer to predict the topic of the review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (springboard)",
   "language": "python",
   "name": "springboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
